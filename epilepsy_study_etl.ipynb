{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9dca8f4",
   "metadata": {},
   "source": [
    "# Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c69a35",
   "metadata": {},
   "source": [
    "# Extract the OMOP dataset from dagshub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276398a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dagshub.streaming import DagsHubFilesystem\n",
    "\n",
    "fs = DagsHubFilesystem(\".\", repo_url=\"https://dagshub.com/DagsHub-Datasets/cmsdesynpuf-omop-dataset\")\n",
    "\n",
    "fs.listdir(\"s3://synpuf-omop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc36e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Unmount any previous filesystem\n",
    "try:\n",
    "    del fs\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 2. Import DagsHub streaming\n",
    "from dagshub.streaming import DagsHubFilesystem\n",
    "import os\n",
    "\n",
    "# 3. Mount the repository\n",
    "fs = DagsHubFilesystem(\n",
    "    \".\", \n",
    "    repo_url=\"https://dagshub.com/DagsHub-Datasets/cmsdesynpuf-omop-dataset\"\n",
    ")\n",
    "\n",
    "# 4. Folder to download\n",
    "source_folder = \"s3://synpuf-omop/cmsdesynpuf100k\"\n",
    "local_folder = \"cmsdesynpuf100k\"\n",
    "\n",
    "# Create local directory if needed\n",
    "os.makedirs(local_folder, exist_ok=True)\n",
    "\n",
    "# 5. List files inside the folder\n",
    "files = fs.listdir(source_folder)\n",
    "print(\"Files found:\", files)\n",
    "\n",
    "# 6. Download each file\n",
    "for filename in files:\n",
    "    src_path = f\"{source_folder}/{filename}\"\n",
    "    dest_path = os.path.join(local_folder, filename)\n",
    "\n",
    "    print(f\"Downloading {filename} ...\")\n",
    "\n",
    "    with fs.open(src_path, \"rb\") as fsrc, open(dest_path, \"wb\") as fdst:\n",
    "        fdst.write(fsrc.read())\n",
    "\n",
    "print(\"Download complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2240f7",
   "metadata": {},
   "source": [
    "# Transform the zipped files into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ff663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# üëâ Set this to the folder where your downloaded files are stored\n",
    "data_dir = Path(\"/Users/maggie/Documents/data_career/Portfolio_Projects/epilepsy_study/cmsdesynpuf100k\")\n",
    "\n",
    "# Create an output directory (optional)\n",
    "output_dir = data_dir / \"csv_extracted\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Loop through all .csv.gz files\n",
    "for gz_file in data_dir.glob(\"*.csv.gz\"):\n",
    "    csv_filename = gz_file.stem  # removes .gz\n",
    "    csv_path = output_dir / csv_filename\n",
    "\n",
    "    print(f\"Extracting: {gz_file.name} -> {csv_filename}\")\n",
    "\n",
    "    # Decompress the file\n",
    "    with gzip.open(gz_file, 'rb') as f_in:\n",
    "        with open(csv_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(\"‚úîÔ∏è All .csv.gz files successfully extracted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gz_file in data_dir.glob(\"*.csv.gz\"):\n",
    "    gz_file.unlink()\n",
    "print(\"üóëÔ∏è Deleted all .csv.gz files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3870cb00",
   "metadata": {},
   "source": [
    "# Install and import the required libraries then connect to PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary pandas sqlalchemy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# UPDATE these details to match your credentials\n",
    "pg_user = \"your_username\"\n",
    "pg_password = \"your_password\"\n",
    "pg_host = \"your_server_name\"\n",
    "pg_port = \"your_port_number\"\n",
    "pg_db = \"your_database_name\"\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_db}\"\n",
    ")\n",
    "\n",
    "engine.connect()\n",
    "print(\"Connected to PostgreSQL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa3b16b",
   "metadata": {},
   "source": [
    "# Load the data from the csv files to your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# UPDATE to your extracted CSV directory\n",
    "csv_dir = Path(\"your/file/path/name\")\n",
    "\n",
    "# Get all CSV files\n",
    "csv_files = list(csv_dir.glob(\"*.csv\"))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files to load.\")\n",
    "\n",
    "for csv_file in tqdm(csv_files):\n",
    "    table_name = csv_file.stem.lower()   # Use filename (no extension) as table\n",
    "    \n",
    "    print(f\"\\nLoading {csv_file.name} ‚Üí {table_name}\")\n",
    "\n",
    "    # Load CSV in chunks to avoid memory issues\n",
    "    chunksize = 50_000\n",
    "\n",
    "    try:\n",
    "        for chunk in pd.read_csv(csv_file, chunksize=chunksize):\n",
    "            chunk.to_sql(\n",
    "                table_name,\n",
    "                engine,\n",
    "                if_exists=\"append\",   # append data if table exists\n",
    "                index=False\n",
    "            )\n",
    "        print(f\"Loaded: {table_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {table_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5044513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = engine.table_names()\n",
    "print(\"Tables in database:\")\n",
    "for t in tables:\n",
    "    print(\" -\", t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
